{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy1 = {}\n",
    "for j in range(4): #episode length\n",
    "    \n",
    "    x = j % 2 \n",
    "    y = 1 - j % 2\n",
    "    policy1[str(j+1)]=[ x, y]\n",
    "    \n",
    "policy1[5] = [1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy2 = {}\n",
    "for j in range(4): #episode length\n",
    "    \n",
    "    x = j % 2 \n",
    "    y = 1 - j % 2\n",
    "    policy2[str(j+1)]=[ y, x]\n",
    "    \n",
    "policy2[5] = [1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import exit, exc_info, argv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#!pip3 install git+https://github.com/slremy/netsapi --user --upgrade\n",
    "\n",
    "from netsapi.challenge import *\n",
    "\n",
    "\n",
    "class CustomAgent:\n",
    "    def __init__(self, environment):\n",
    "        self.environment = environment\n",
    "\n",
    "    def generate(self):\n",
    "        best_policy = None\n",
    "        best_reward = -float('Inf')\n",
    "        candidates = []\n",
    "        try:\n",
    "            # Agents should make use of 20 episodes in each training run, if making sequential decisions\n",
    "            for i in range(20):\n",
    "                self.environment.reset()\n",
    "                if random.random() > 0.5:\n",
    "                    candidates.append(policy1)\n",
    "                else: \n",
    "                    candidates.append(policy2)\n",
    "                \n",
    "            rewards = self.environment.evaluatePolicy(candidates)\n",
    "            best_policy = candidates[np.argmax(rewards)]\n",
    "            best_reward = rewards[np.argmax(rewards)]\n",
    "        \n",
    "        except (KeyboardInterrupt, SystemExit):\n",
    "            print(exc_info())\n",
    "            \n",
    "        return best_policy, best_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105  Evaluations Remaining\n",
      "105  Evaluations Remaining\n",
      "105  Evaluations Remaining\n",
      "105  Evaluations Remaining\n",
      "105  Evaluations Remaining\n",
      "105  Evaluations Remaining\n",
      "105  Evaluations Remaining\n",
      "105  Evaluations Remaining\n",
      "105  Evaluations Remaining\n",
      "105  Evaluations Remaining\n",
      "511.4049453665883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<netsapi.challenge.EvaluateChallengeSubmission at 0x1c5b8801e48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EvaluateChallengeSubmission(ChallengeSeqDecEnvironment, CustomAgent, \"submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
